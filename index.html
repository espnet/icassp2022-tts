<!DOCTYPE html>











<html lang="en-us">
  <head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />

  
  <title> - ICASSP2022 ESPnet2-TTS</title>

  
  
  <meta name="description" content="ESPnet2-TTS: Extending the Edge of TTS Research Submitted to ICASSP 2022
Authors  Tomoki Hayashi (Human Dataware Lab. Co., Ltd. / Nagoya University) Ryuichi Yamamoto (LINE Corp.) Takenori Yoshimura (Nagoya Institute of Technology) Peter Wu (Carnegie Mellon University) Jiatong Shi (Carnegie Mellon University) Takaaki Saeki (The University of Tokyo) Yooncheol Ju (AIRS Company, Hyundai Motor Group) Yusuke Yasuda (Nagoya University) Shinnosuke Takamichi (The University of Tokyo) Shinji Watanabe (Carnegie Mellon University)  Abstract This paper describes ESPnet2-TTS, an end-to-end text-to-speech (E2E-TTS) toolkit." />
  <meta name="author" content="" />
  

  
  
  
  
  
  
  <link rel="preload stylesheet" as="style" href="https://espnet.github.io/icassp2022-tts/app.min.css" />

  
  <link rel="preload stylesheet" as="style" href="https://espnet.github.io/icassp2022-tts/an-old-hope.min.css" />
  <script
    defer
    src="https://espnet.github.io/icassp2022-tts/highlight.min.js"
    onload="hljs.initHighlightingOnLoad();"
  ></script>
  

  
  <link rel="preload" as="image" href="https://espnet.github.io/icassp2022-tts/theme.png" />

  

  
  <link rel="icon" href="https://espnet.github.io/icassp2022-tts/favicon.ico" />
  <link rel="apple-touch-icon" href="https://espnet.github.io/icassp2022-tts/apple-touch-icon.png" />

  
  <meta name="generator" content="Hugo 0.79.1" />

  
  

  
  
  
  
  
  
  
  <meta property="og:title" content="" />
<meta property="og:description" content="ESPnet2-TTS: Extending the Edge of TTS Research Submitted to ICASSP 2022
Authors  Tomoki Hayashi (Human Dataware Lab. Co., Ltd. / Nagoya University) Ryuichi Yamamoto (LINE Corp.) Takenori Yoshimura (Nagoya Institute of Technology) Peter Wu (Carnegie Mellon University) Jiatong Shi (Carnegie Mellon University) Takaaki Saeki (The University of Tokyo) Yooncheol Ju (AIRS Company, Hyundai Motor Group) Yusuke Yasuda (Nagoya University) Shinnosuke Takamichi (The University of Tokyo) Shinji Watanabe (Carnegie Mellon University)  Abstract This paper describes ESPnet2-TTS, an end-to-end text-to-speech (E2E-TTS) toolkit." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://espnet.github.io/icassp2022-tts/" />
<meta property="article:published_time" content="2021-10-10T00:00:00+00:00" />
<meta property="article:modified_time" content="2021-10-10T00:00:00+00:00" />

  
  <meta itemprop="name" content="">
<meta itemprop="description" content="ESPnet2-TTS: Extending the Edge of TTS Research Submitted to ICASSP 2022
Authors  Tomoki Hayashi (Human Dataware Lab. Co., Ltd. / Nagoya University) Ryuichi Yamamoto (LINE Corp.) Takenori Yoshimura (Nagoya Institute of Technology) Peter Wu (Carnegie Mellon University) Jiatong Shi (Carnegie Mellon University) Takaaki Saeki (The University of Tokyo) Yooncheol Ju (AIRS Company, Hyundai Motor Group) Yusuke Yasuda (Nagoya University) Shinnosuke Takamichi (The University of Tokyo) Shinji Watanabe (Carnegie Mellon University)  Abstract This paper describes ESPnet2-TTS, an end-to-end text-to-speech (E2E-TTS) toolkit.">
<meta itemprop="datePublished" content="2021-10-10T00:00:00+00:00" />
<meta itemprop="dateModified" content="2021-10-10T00:00:00+00:00" />
<meta itemprop="wordCount" content="1376">



<meta itemprop="keywords" content="" />

  
  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content=""/>
<meta name="twitter:description" content="ESPnet2-TTS: Extending the Edge of TTS Research Submitted to ICASSP 2022
Authors  Tomoki Hayashi (Human Dataware Lab. Co., Ltd. / Nagoya University) Ryuichi Yamamoto (LINE Corp.) Takenori Yoshimura (Nagoya Institute of Technology) Peter Wu (Carnegie Mellon University) Jiatong Shi (Carnegie Mellon University) Takaaki Saeki (The University of Tokyo) Yooncheol Ju (AIRS Company, Hyundai Motor Group) Yusuke Yasuda (Nagoya University) Shinnosuke Takamichi (The University of Tokyo) Shinji Watanabe (Carnegie Mellon University)  Abstract This paper describes ESPnet2-TTS, an end-to-end text-to-speech (E2E-TTS) toolkit."/>

  
  
</head>


  <body class="not-ready" data-menu="false">
    <header class="header">
  
  <p class="logo">
    <a class="site-name" href="https://espnet.github.io/icassp2022-tts/">ICASSP2022 ESPnet2-TTS</a><a class="btn-dark"></a>
  </p>
  

  <script>
    let bodyClx = document.body.classList;
    let btnDark = document.querySelector('.btn-dark');
    let sysDark = window.matchMedia('(prefers-color-scheme: dark)');
    let darkVal = localStorage.getItem('dark');

    let setDark = (isDark) => {
      bodyClx[isDark ? 'add' : 'remove']('dark');
      localStorage.setItem('dark', isDark ? 'yes' : 'no');
    };

    setDark(darkVal ? darkVal === 'yes' : sysDark.matches);
    requestAnimationFrame(() => bodyClx.remove('not-ready'));

    btnDark.addEventListener('click', () => setDark(!bodyClx.contains('dark')));
    sysDark.addEventListener('change', (event) => setDark(event.matches));
  </script>

  
  

  
</header>


    <main class="main">

<article class="post-single">
  <header class="post-title">
    <p>
      <time>:date_medium</time>
      
    </p>
    <h1></h1>
  </header>
  <section class="post-content"><h1 id="espnet2-tts-extending-the-edge-of-tts-research">ESPnet2-TTS: Extending the Edge of TTS Research</h1>
<p>Submitted to ICASSP 2022</p>
<h2 id="authors">Authors</h2>
<ul>
<li>Tomoki Hayashi (Human Dataware Lab. Co., Ltd. / Nagoya University)</li>
<li>Ryuichi Yamamoto (LINE Corp.)</li>
<li>Takenori Yoshimura (Nagoya Institute of Technology)</li>
<li>Peter Wu (Carnegie Mellon University)</li>
<li>Jiatong Shi (Carnegie Mellon University)</li>
<li>Takaaki Saeki (The University of Tokyo)</li>
<li>Yooncheol Ju (AIRS Company, Hyundai Motor Group)</li>
<li>Yusuke Yasuda (Nagoya University)</li>
<li>Shinnosuke Takamichi (The University of Tokyo)</li>
<li>Shinji Watanabe (Carnegie Mellon University)</li>
</ul>
<h2 id="abstract">Abstract</h2>
<p>This paper describes ESPnet2-TTS, an end-to-end text-to-speech (E2E-TTS) toolkit. ESPnet2-TTS extends our earlier version, ESPnet-TTS, by adding many new features, including: on-the-fly flexible pre-processing, joint training with neural vocoders, and state-of-the-art TTS models with extensions like full-band E2E text-to-waveform modeling, which simplify the training pipeline and further enhance TTS performance.
The unified design of our recipes enables users to quickly reproduce state-of-the-art E2E-TTS results.
We also provide many pre-trained models in a unified Python interface for inference, offering a quick means for users to generate baseline samples and build demos.
Experimental evaluations with English and Japanese corpora demonstrate that our provided models synthesize utterances comparable to ground-truth ones, achieving state-of-the-art TTS performance.
The toolkit is available online at <a href="https://github.com/espnet/espnet">https://github.com/espnet/espnet</a>.</p>
<h2 id="demo">Demo</h2>
<p>You can try real-time demo in <a href="https://colab.research.google.com/github/espnet/notebook/blob/master/espnet2_tts_realtime_demo.ipynb">Google colab</a>.</p>
<h2 id="example-of-ljspeech-english-single-speaker">Example of LJSpeech (English single speaker)</h2>
<ul>
<li><strong>Transformer-TTS (icassp2020)</strong>: Transformer-TTS + Mixture of density WaveNet vocoder with noise shaping. Our preivous best model.</li>
<li><strong>CFS2</strong>: Conformer-FastSpeech2 + HiFiGAN. Each model was separately trained.</li>
<li><strong>CFS2 (ft)</strong>: Same as the above model, but HiFi-GAN was fine-tuned with ground-truth aligned mel spectrograms.</li>
<li><strong>CFS2 (joint-ft)</strong>: Same as the above model, but both models were jointly fine-tuned.</li>
<li><strong>CFS2 (joint-tr)</strong>: Same as the above model, but both models were jointly trained from the scratch.</li>
<li><strong>VITS</strong>: End-to-end text-to-waveform model, VITS.</li>
</ul>
<p>All models used <code>g2p_en</code> as the G2P function.<br>
You can find the detailed configurations in <a href="https://github.com/espnet/espnet/tree/master/egs2/ljspeech/tts1/conf/tuning"><code>egs2/ljspeech/tts1/conf/tuning</code></a>.</p>
<p><strong>LJ050-0030</strong>: The Commission also recommends</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Groundtruth</strong></td>
<td><strong>Transformer-TTS (icassp2020)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/ljspeech/gt/LJ050-0030.wav"/></audio></td>
<td><audio controls="" ><source src="wav/ljspeech/icassp2020/LJ050-0030_gen.wav"/></audio></td>
</tr>
<tr>
<td><strong>CFS2</strong></td>
<td><strong>CFS2 (ft)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/ljspeech/cfs2/LJ050-0030.wav"/></audio></td>
<td><audio controls="" ><source src="wav/ljspeech/cfs2_ft/LJ050-0030.wav"/></audio></td>
</tr>
<tr>
<td><strong>CFS2 (joint-ft)</strong></td>
<td><strong>CFS2 (joint-tr)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/ljspeech/cfs2_joint_ft/LJ050-0030.wav"/></audio></td>
<td><audio controls="" ><source src="wav/ljspeech/cfs2_joint_tr/LJ050-0030.wav"/></audio></td>
</tr>
<tr>
<td><strong>VITS</strong></td>
<td></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/ljspeech/vits/LJ050-0030.wav"/></audio></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>LJ050-0040</strong>: and reports from other agencies which independently evaluate their information for potential sources of danger.</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Groundtruth</strong></td>
<td><strong>Transformer-TTS (icassp2020)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/ljspeech/gt/LJ050-0040.wav"/></audio></td>
<td><audio controls="" ><source src="wav/ljspeech/icassp2020/LJ050-0040_gen.wav"/></audio></td>
</tr>
<tr>
<td><strong>CFS2</strong></td>
<td><strong>CFS2 (ft)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/ljspeech/cfs2/LJ050-0040.wav"/></audio></td>
<td><audio controls="" ><source src="wav/ljspeech/cfs2_ft/LJ050-0040.wav"/></audio></td>
</tr>
<tr>
<td><strong>CFS2 (joint-ft)</strong></td>
<td><strong>CFS2 (joint-tr)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/ljspeech/cfs2_joint_ft/LJ050-0040.wav"/></audio></td>
<td><audio controls="" ><source src="wav/ljspeech/cfs2_joint_tr/LJ050-0040.wav"/></audio></td>
</tr>
<tr>
<td><strong>VITS</strong></td>
<td></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/ljspeech/vits/LJ050-0040.wav"/></audio></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>LJ050-0050</strong>: As a result of these studies, the planning document submitted by the Secretary of the Treasury to the Bureau of the Budget on August thirty-one,</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Groundtruth</strong></td>
<td><strong>Transformer-TTS (icassp2020)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/ljspeech/gt/LJ050-0050.wav"/></audio></td>
<td><audio controls="" ><source src="wav/ljspeech/icassp2020/LJ050-0050_gen.wav"/></audio></td>
</tr>
<tr>
<td><strong>CFS2</strong></td>
<td><strong>CFS2 (ft)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/ljspeech/cfs2/LJ050-0050.wav"/></audio></td>
<td><audio controls="" ><source src="wav/ljspeech/cfs2_ft/LJ050-0050.wav"/></audio></td>
</tr>
<tr>
<td><strong>CFS2 (joint-ft)</strong></td>
<td><strong>CFS2 (joint-tr)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/ljspeech/cfs2_joint_ft/LJ050-0050.wav"/></audio></td>
<td><audio controls="" ><source src="wav/ljspeech/cfs2_joint_tr/LJ050-0050.wav"/></audio></td>
</tr>
<tr>
<td><strong>VITS</strong></td>
<td></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/ljspeech/vits/LJ050-0050.wav"/></audio></td>
<td></td>
</tr>
</tbody>
</table>
<h3 id="analysis-of-wrong-g2p-results">Analysis of wrong G2P results</h3>
<ul>
<li><strong>CFS2 (g2p_en)</strong>: Conformer-FastSpeech2 + HiFiGAN with <code>g2p_en</code> as the G2P function.</li>
<li><strong>CFS2 (espeak_ng)</strong>: Conformer-FastSpeech2 + HiFiGAN with <code>espeak_ng</code> as the G2P function.</li>
<li><strong>VITS (g2p_en)</strong>: VITS with <code>g2p_en</code> as the G2P function.</li>
<li><strong>VITS (espeak_ng)</strong>: VITS with <code>espeak_ng</code> as the G2P function.</li>
</ul>
<p><strong>LJ050-0069</strong>: the Secret Service had received from the <strong>FBI</strong> some nine thousand reports on members of the Communist Party.</p>
<p><strong>g2p_en</strong></p>
<pre><code>DH AH0 &lt;space&gt; S IY1 K R AH0 T &lt;space&gt; S ER1 V AH0 S &lt;space&gt; HH AE1 D &lt;space&gt; R AH0 S IY1 V D &lt;space&gt; F R AH1 M &lt;space&gt; DH AH0 &lt;space&gt; B AY1 &lt;space&gt; S AH1 M &lt;space&gt; N AY1 N &lt;space&gt; TH AW1 Z AH0 N D &lt;space&gt; R IH0 P AO1 R T S &lt;space&gt; AA1 N &lt;space&gt; M EH1 M B ER0 Z &lt;space&gt; AH1 V &lt;space&gt; DH AH0 &lt;space&gt; K AA1 M Y AH0 N AH0 S T &lt;space&gt; P AA1 R T IY0 &lt;space&gt; .
</code></pre><p><strong>espeak_ng</strong></p>
<pre><code>ð ə &lt;space&gt; s ˈ i ː k ɹ ᵻ t &lt;space&gt; s ˈ ɜ ː v ɪ s &lt;space&gt; h æ d &lt;space&gt; ɹ ᵻ s ˈ i ː v d &lt;space&gt; f ɹ ʌ m ð ɪ &lt;space&gt; ˌ ɛ f b ˌ i ː ˈ a ɪ &lt;space&gt; s ˌ ʌ m &lt;space&gt; n ˈ a ɪ n &lt;space&gt; θ ˈ a ʊ z ə n d &lt;space&gt; ɹ ᵻ p ˈ o ː ɹ t s &lt;space&gt; ˌ ɔ n &lt;space&gt; m ˈ ɛ m b ɚ z &lt;space&gt; ʌ v ð ə &lt;space&gt; k ˈ ɑ ː m j u ː n ˌ ɪ s t &lt;space&gt; p ˈ ɑ ː ɹ ɾ i .`
</code></pre><table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>CFS2 (g2p_en)</strong></td>
<td><strong>CFS2 (espeak_ng)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/ljspeech/cfs2/LJ050-0069.wav"/></audio></td>
<td><audio controls="" ><source src="wav/ljspeech/cfs2_espeak/LJ050-0069.wav"/></audio></td>
</tr>
<tr>
<td><strong>VITS (g2p_en)</strong></td>
<td><strong>VITS (espeak_ng)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/ljspeech/vits/LJ050-0069.wav"/></audio></td>
<td><audio controls="" ><source src="wav/ljspeech/vits_espeak/LJ050-0069.wav"/></audio></td>
</tr>
</tbody>
</table>
<p><strong>LJ050-0070</strong>: The <strong>FBI</strong> now transmits information on all defectors, a category which would, of course, have included Oswald.</p>
<p><strong>g2p_en</strong></p>
<pre><code>DH AH0 &lt;space&gt; B AY1 &lt;space&gt; N AW1 &lt;space&gt; T R AE0 N Z M IH1 T S &lt;space&gt; IH2 N F ER0 M EY1 SH AH0 N &lt;space&gt; AA1 N &lt;space&gt; AO1 L &lt;space&gt; D IH0 F EH1 K T ER0 Z &lt;space&gt; , &lt;space&gt; AH0 &lt;space&gt; K AE1 T AH0 G AO2 R IY0 &lt;space&gt; W IH1 CH &lt;space&gt; W UH1 D &lt;space&gt; , &lt;space&gt; AH1 V &lt;space&gt; K AO1 R S &lt;space&gt; , &lt;space&gt; HH AE1 V &lt;space&gt; IH0 N K L UW1 D AH0 D &lt;space&gt; AO1 Z W AO0 L D &lt;space&gt; .
</code></pre><p><strong>espeak_ng</strong></p>
<pre><code>ð ɪ &lt;space&gt; ˌ ɛ f b ˌ i ː ˈ a ɪ &lt;space&gt; n ˈ a ʊ &lt;space&gt; t ɹ æ n s m ˈ ɪ t s &lt;space&gt; ˌ ɪ n f ɚ m ˈ e ɪ ʃ ə n &lt;space&gt; ˌ ɔ n &lt;space&gt; ˈ ɔ ː l &lt;space&gt; d ᵻ f ˈ ɛ k t ɚ z , &lt;space&gt; ɐ &lt;space&gt; k ˈ æ ɾ ɪ ɡ ɚ ɹ i &lt;space&gt; w ˌ ɪ t ʃ &lt;space&gt; w ˈ ʊ d , &lt;space&gt; ʌ v &lt;space&gt; k ˈ o ː ɹ s , &lt;space&gt; h æ v &lt;space&gt; ɪ ŋ k l ˈ u ː d ᵻ d &lt;space&gt; ˈ ɑ ː s w ə l d .
</code></pre><table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>CFS2 (g2p_en)</strong></td>
<td><strong>CFS2 (espeak_ng)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/ljspeech/cfs2/LJ050-0070.wav"/></audio></td>
<td><audio controls="" ><source src="wav/ljspeech/cfs2_espeak/LJ050-0070.wav"/></audio></td>
</tr>
<tr>
<td><strong>VITS (g2p_en)</strong></td>
<td><strong>VITS (espeak_ng)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/ljspeech/vits/LJ050-0070.wav"/></audio></td>
<td><audio controls="" ><source src="wav/ljspeech/vits_espeak/LJ050-0070.wav"/></audio></td>
</tr>
</tbody>
</table>
<h2 id="example-of-vctk-english-multi-speaker">Example of VCTK (English multi-speaker)</h2>
<ul>
<li><strong>Groundtruth</strong>: Groundtruth speech.</li>
<li><strong>SID-VITS</strong>: VITS with one-hot speaker ID (SID) embeddings. Since this model cannot deal with unknown speakers, we trained it with all of the speakers.</li>
<li><strong>X-VITS (avg)</strong>: VITS with pre-trained X-vectors instead of one-hot speaker ID embeddings. This model was trained with all speakers except for the evaluation ones in the unseen speaker condition. For inference, we used X-vectors averaged over all the utterances of the target speaker except for the evaluation utterances.</li>
<li><strong>X-VITS (random)</strong>: The same as the above model except it used X-vectors extracted from a single utterance of the target speaker. This datapoint was randomly selected from all utterances of the speaker excluding the evaluation utterances.</li>
</ul>
<p>All models used <code>espeak_ng</code> as the G2P function.<br>
You can find the detailed configurations in <a href="https://github.com/espnet/espnet/tree/master/egs2/vctk/tts1/conf/tuning"><code>egs2/vctk/tts1/conf/tuning</code></a>.</p>
<h3 id="seen-speaker-condition">Seen-speaker condition</h3>
<p><strong>p241_364</strong>: We have to be sure that the taxation system can work.</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>GT</strong></td>
<td><strong>SID-VITS</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/vctk/gt_subset_b/p241_364.wav"/></audio></td>
<td><audio controls="" ><source src="wav/vctk/sid_vits_subset_b/p241_364.wav"/></audio></td>
</tr>
<tr>
<td><strong>X-VITS (avg)</strong></td>
<td><strong>X-VITS (random)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/vctk/x_avg_vits_subset_b/p241_364.wav"/></audio></td>
<td><audio controls="" ><source src="wav/vctk/x_random_vits_subset_b/p241_364.wav"/></audio></td>
</tr>
</tbody>
</table>
<p><strong>p245_350</strong>: Despite his senior position, he did not know in advance.</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>GT</strong></td>
<td><strong>SID-VITS</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/vctk/gt_subset_b/p245_350.wav"/></audio></td>
<td><audio controls="" ><source src="wav/vctk/sid_vits_subset_b/p245_350.wav"/></audio></td>
</tr>
<tr>
<td><strong>X-VITS (avg)</strong></td>
<td><strong>X-VITS (random)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/vctk/x_avg_vits_subset_b/p245_350.wav"/></audio></td>
<td><audio controls="" ><source src="wav/vctk/x_random_vits_subset_b/p245_350.wav"/></audio></td>
</tr>
</tbody>
</table>
<p><strong>p265_343</strong>: It&rsquo;s not pretty, but it&rsquo;s effective.</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>GT</strong></td>
<td><strong>SID-VITS</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/vctk/gt_subset_b/p265_343.wav"/></audio></td>
<td><audio controls="" ><source src="wav/vctk/sid_vits_subset_b/p265_343.wav"/></audio></td>
</tr>
<tr>
<td><strong>X-VITS (avg)</strong></td>
<td><strong>X-VITS (random)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/vctk/x_avg_vits_subset_b/p265_343.wav"/></audio></td>
<td><audio controls="" ><source src="wav/vctk/x_random_vits_subset_b/p265_343.wav"/></audio></td>
</tr>
</tbody>
</table>
<p><strong>p333_416</strong>: Their courage, and their honesty, should be respected.</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>GT</strong></td>
<td><strong>SID-VITS</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/vctk/gt_subset_b/p333_416.wav"/></audio></td>
<td><audio controls="" ><source src="wav/vctk/sid_vits_subset_b/p333_416.wav"/></audio></td>
</tr>
<tr>
<td><strong>X-VITS (avg)</strong></td>
<td><strong>X-VITS (random)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/vctk/x_avg_vits_subset_b/p333_416.wav"/></audio></td>
<td><audio controls="" ><source src="wav/vctk/x_random_vits_subset_b/p333_416.wav"/></audio></td>
</tr>
</tbody>
</table>
<h3 id="unseen-speaker-condition">Unseen-speaker condition</h3>
<p><strong>p227_393</strong>: You have to rely on each other.</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>GT</strong></td>
<td><strong>SID-VITS</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/vctk/gt_subset_a/p227_393.wav"/></audio></td>
<td><audio controls="" ><source src="wav/vctk/sid_vits_subset_a/p227_393.wav"/></audio></td>
</tr>
<tr>
<td><strong>X-VITS (avg)</strong></td>
<td><strong>X-VITS (random)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/vctk/x_avg_vits_subset_a/p227_393.wav"/></audio></td>
<td><audio controls="" ><source src="wav/vctk/x_random_vits_subset_a/p227_393.wav"/></audio></td>
</tr>
</tbody>
</table>
<p><strong>p228_362</strong>: It took about an hour for the gas to clear.</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>GT</strong></td>
<td><strong>SID-VITS</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/vctk/gt_subset_a/p228_362.wav"/></audio></td>
<td><audio controls="" ><source src="wav/vctk/sid_vits_subset_a/p228_362.wav"/></audio></td>
</tr>
<tr>
<td><strong>X-VITS (avg)</strong></td>
<td><strong>X-VITS (random)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/vctk/x_avg_vits_subset_a/p228_362.wav"/></audio></td>
<td><audio controls="" ><source src="wav/vctk/x_random_vits_subset_a/p228_362.wav"/></audio></td>
</tr>
</tbody>
</table>
<p><strong>p300_391</strong>: Form and structure are his music.</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>GT</strong></td>
<td><strong>SID-VITS</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/vctk/gt_subset_a/p300_391.wav"/></audio></td>
<td><audio controls="" ><source src="wav/vctk/sid_vits_subset_a/p300_391.wav"/></audio></td>
</tr>
<tr>
<td><strong>X-VITS (avg)</strong></td>
<td><strong>X-VITS (random)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/vctk/x_avg_vits_subset_a/p300_391.wav"/></audio></td>
<td><audio controls="" ><source src="wav/vctk/x_random_vits_subset_a/p300_391.wav"/></audio></td>
</tr>
</tbody>
</table>
<p><strong>p304_415</strong>: Parliament was evenly divided on the issue.</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>GT</strong></td>
<td><strong>SID-VITS</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/vctk/gt_subset_a/p304_415.wav"/></audio></td>
<td><audio controls="" ><source src="wav/vctk/sid_vits_subset_a/p304_415.wav"/></audio></td>
</tr>
<tr>
<td><strong>X-VITS (avg)</strong></td>
<td><strong>X-VITS (random)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/vctk/x_avg_vits_subset_a/p304_415.wav"/></audio></td>
<td><audio controls="" ><source src="wav/vctk/x_random_vits_subset_a/p304_415.wav"/></audio></td>
</tr>
</tbody>
</table>
<h2 id="example-of-jsut-japanese-single-speaker">Example of JSUT (Japanese single speaker)</h2>
<ul>
<li><strong>Groundtruth (22k)</strong>: Groundtruth with 22.05 kHz sampling rate.</li>
<li><strong>Groundtruth (44k)</strong>: Groundtruth with 44.1 kHz sampling rate.</li>
<li><strong>Tacotron2</strong>: Tacotron2 + HiFiGAN. Each model was separately trained.</li>
<li><strong>Transformer-TTS</strong>: Transformer-TTS + HiFiGAN. Each model was separately trained.</li>
<li><strong>CFS2</strong>: Conformer-FastSpeech2 + HiFiGAN. Each model was separately trained.</li>
<li><strong>CFS2 (ft)</strong>: Same as the above model, but HiFi-GAN was fine-tuned with ground-truth aligned mel spectrograms.</li>
<li><strong>VITS</strong>: VITS trained with 22.05 kHz sampling rate.</li>
<li><strong>FB-VITS</strong>: Full-band VITS trained with 44.1 kHz sampling rate.</li>
</ul>
<p>All models used <code>pyopenjtalk_prosody</code> as the G2P function.<br>
You can find the detailed configurations in <a href="https://github.com/espnet/espnet/tree/master/egs2/jsut/tts1/conf/tuning"><code>egs2/jsut/tts1/conf/tuning</code></a>.</p>
<p><strong>BASIC5000_0001</strong>: 水をマレーシアから買わなくてはならないのです。</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>GT (22k)</strong></td>
<td><strong>GT (44k)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/jsut/gt_22k/BASIC5000_0001.wav"/></audio></td>
<td><audio controls="" ><source src="wav/jsut/gt_44k/BASIC5000_0001.wav"/></audio></td>
</tr>
<tr>
<td><strong>Tacotron2</strong></td>
<td><strong>Transformer-TTS</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/jsut/taco2_22k/BASIC5000_0001.wav"/></audio></td>
<td><audio controls="" ><source src="wav/jsut/transformer_22k/BASIC5000_0001.wav"/></audio></td>
</tr>
<tr>
<td><strong>CFS2</strong></td>
<td><strong>CFS2 (ft)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/jsut/cfs2_22k/BASIC5000_0001.wav"/></audio></td>
<td><audio controls="" ><source src="wav/jsut/cfs2_ft_22k/BASIC5000_0001.wav"/></audio></td>
</tr>
<tr>
<td><strong>VITS</strong></td>
<td><strong>FB-VITS</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/jsut/vits_22k/BASIC5000_0001.wav"/></audio></td>
<td><audio controls="" ><source src="wav/jsut/vits_44k/BASIC5000_0001.wav"/></audio></td>
</tr>
</tbody>
</table>
<p><strong>BASIC5000_0005</strong>: 血圧は、健康のパロメーターとして重要である。</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>GT (22k)</strong></td>
<td><strong>GT (44k)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/jsut/gt_22k/BASIC5000_0005.wav"/></audio></td>
<td><audio controls="" ><source src="wav/jsut/gt_44k/BASIC5000_0005.wav"/></audio></td>
</tr>
<tr>
<td><strong>Tacotron2</strong></td>
<td><strong>Transformer-TTS</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/jsut/taco2_22k/BASIC5000_0005.wav"/></audio></td>
<td><audio controls="" ><source src="wav/jsut/transformer_22k/BASIC5000_0005.wav"/></audio></td>
</tr>
<tr>
<td><strong>CFS2</strong></td>
<td><strong>CFS2 (ft)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/jsut/cfs2_22k/BASIC5000_0005.wav"/></audio></td>
<td><audio controls="" ><source src="wav/jsut/cfs2_ft_22k/BASIC5000_0005.wav"/></audio></td>
</tr>
<tr>
<td><strong>VITS</strong></td>
<td><strong>FB-VITS</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/jsut/vits_22k/BASIC5000_0005.wav"/></audio></td>
<td><audio controls="" ><source src="wav/jsut/vits_44k/BASIC5000_0005.wav"/></audio></td>
</tr>
</tbody>
</table>
<p><strong>BASIC5000_0009</strong>: 無罪の人々は、もちろん放免された。</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>GT (22k)</strong></td>
<td><strong>GT (44k)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/jsut/gt_22k/BASIC5000_0009.wav"/></audio></td>
<td><audio controls="" ><source src="wav/jsut/gt_44k/BASIC5000_0009.wav"/></audio></td>
</tr>
<tr>
<td><strong>Tacotron2</strong></td>
<td><strong>Transformer-TTS</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/jsut/taco2_22k/BASIC5000_0009.wav"/></audio></td>
<td><audio controls="" ><source src="wav/jsut/transformer_22k/BASIC5000_0009.wav"/></audio></td>
</tr>
<tr>
<td><strong>CFS2</strong></td>
<td><strong>CFS2 (ft)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/jsut/cfs2_22k/BASIC5000_0009.wav"/></audio></td>
<td><audio controls="" ><source src="wav/jsut/cfs2_ft_22k/BASIC5000_0009.wav"/></audio></td>
</tr>
<tr>
<td><strong>VITS</strong></td>
<td><strong>FB-VITS</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/jsut/vits_22k/BASIC5000_0009.wav"/></audio></td>
<td><audio controls="" ><source src="wav/jsut/vits_44k/BASIC5000_0009.wav"/></audio></td>
</tr>
</tbody>
</table>
<h2 id="example-of-jvs-japanese-single-speaker-adaptation">Example of JVS (Japanese single speaker adaptation)</h2>
<ul>
<li><strong>Groundtruth</strong>: Groundtruth speech..</li>
<li><strong>VITS</strong>: VITS adapted with 100 utteracnes. The base model was trained on JSUT with 22.05 kHz.</li>
</ul>
<p>All models used <code>pyopenjtalk_prosody</code> as the G2P function.<br>
You can find the detailed configurations in <a href="https://github.com/espnet/espnet/tree/master/egs2/jvs/tts1/conf/tuning"><code>egs2/jvs/tts1/conf/tuning</code></a>.</p>
<p><strong>BASIC5000_0408</strong>: 私もパーティーに来るべきだ、と、彼はつけ加えた。</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>GT (jvs001)</strong></td>
<td><strong>VITS (jvs001)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/jvs/jvs001_gt/jvs001_BASIC5000_0408.wav"/></audio></td>
<td><audio controls="" ><source src="wav/jvs/jvs001_vits/jvs001_BASIC5000_0408.wav"/></audio></td>
</tr>
</tbody>
</table>
<p><strong>BASIC5000_0261</strong>: 紙をとじるのに、ホチキスはとても便利だ。</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>GT (jvs010)</strong></td>
<td><strong>VITS (jvs010)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/jvs/jvs010_gt/jvs010_BASIC5000_0261.wav"/></audio></td>
<td><audio controls="" ><source src="wav/jvs/jvs010_vits/jvs010_BASIC5000_0261.wav"/></audio></td>
</tr>
</tbody>
</table>
<p><strong>BASIC5000_0238</strong>: 西欧諸国は、この問題に対する日本の姿勢を、激しく非難しています。</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>GT (jvs054)</strong></td>
<td><strong>VITS (jvs054)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/jvs/jvs054_gt/jvs054_BASIC5000_0238.wav"/></audio></td>
<td><audio controls="" ><source src="wav/jvs/jvs054_vits/jvs054_BASIC5000_0238.wav"/></audio></td>
</tr>
</tbody>
</table>
<p><strong>BASIC5000_0012</strong>: 溺れかかっていた乗客は、すべて救助された。</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>GT (jvs092)</strong></td>
<td><strong>VITS (jvs092)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/jvs/jvs092_gt/jvs092_BASIC5000_0012.wav"/></audio></td>
<td><audio controls="" ><source src="wav/jvs/jvs092_vits/jvs092_BASIC5000_0012.wav"/></audio></td>
</tr>
</tbody>
</table>
<h2 id="contact">Contact</h2>
<ul>
<li><a href="https://kan-bayashi.github.io/">Tomoki Hayashi</a> (hayashi.tomoki<at>g.sp.m.is.nagoya-u.ac.jp)</li>
</ul>
</section>

  
  

  
  
  

  
  
</article>

</main>

    <footer class="footer">
  <p>&copy; 2021 <a href="https://espnet.github.io/icassp2022-tts/">ICASSP2022 ESPnet2-TTS</a></p>
  <p>Powered by <a href="https://gohugo.io/" rel="noopener" target="_blank">Hugo️️</a>️</p>
  <p>
    <a href="https://github.com/nanxiaobei/hugo-paper" rel="noopener" target="_blank">Paper 5.1</a>
  </p>
</footer>

  </body>
</html>
